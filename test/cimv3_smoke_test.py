"""
Test script for CIMv3-compatible picoGPT model
Verify the updated Block structure: MHA ‚Üí FFN ‚Üí LN2
"""

import torch
import sys
import os

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from model.pico_model import PicoGPTConfig, PicoGPT, Block

def test_cimv3_block_structure():
    """Test the CIMv3-compatible block structure"""
    print("Testing CIMv3-Compatible picoGPT Block Structure")
    print("=" * 60)

    # Create a CIMv3-compatible test config
    config = PicoGPTConfig(
        block_size=128,
        vocab_size=65,
        n_layer=3,
        n_head=2,      # CIMv3 optimized: 128 / 2 = 64 d_head
        n_embd=128,    # CIMv3 compatible dimension
        dropout=0.0,   # No dropout for testing
        bias=False     # CIMv3 prefers bias-free operations
    )

    # Test individual block
    block = Block(config)
    print("Block structure:")
    print(f"  - attn: {type(block.attn).__name__}")
    print(f"  - mlp: {type(block.mlp).__name__} with ReLU activation")
    print(f"  - ln_2: {type(block.ln_2).__name__}")
    print(f"  - NO ln_1: ‚úì Removed for CIMv3 compatibility")

    # Verify ReLU activation
    mlp_activation = type(block.mlp.relu).__name__
    if mlp_activation == "ReLU":
        print(f"  - Activation: ‚úì ReLU (CIMv3 compatible)")
    else:
        print(f"  - Activation: ‚úó {mlp_activation} (should be ReLU)")
        return False

    # Test forward pass
    batch_size, seq_len = 2, 10
    x = torch.randn(batch_size, seq_len, config.n_embd)

    print(f"\nTesting forward pass:")
    print(f"  Input shape: {x.shape}")

    with torch.no_grad():
        output = block(x)
        print(f"  Output shape: {output.shape}")
        print(f"  Forward pass: ‚úì Success")

    return True

def test_full_model():
    """Test the full CIMv3-compatible model"""
    print("\n" + "=" * 60)
    print("Testing Full CIMv3-Compatible picoGPT Model")
    print("=" * 60)

    config = PicoGPTConfig(
        block_size=128,
        vocab_size=65,
        n_layer=3,
        n_head=2,      # CIMv3 optimized: 128 / 2 = 64 d_head
        n_embd=128,    # CIMv3 compatible dimension
        dropout=0.0,
        bias=False
    )

    model = PicoGPT(config)

    # Print model structure
    print("Model architecture:")
    for name, module in model.named_modules():
        if 'ln_1' in name:
            print(f"  ERROR: Found ln_1 in {name} - should be removed!")
        elif 'ln_2' in name:
            print(f"  ‚úì {name}: {type(module).__name__}")
        elif 'attn' in name and isinstance(module, type(model.transformer.h[0].attn)):
            print(f"  ‚úì {name}: {type(module).__name__}")
        elif 'mlp' in name and isinstance(module, type(model.transformer.h[0].mlp)):
            print(f"  ‚úì {name}: {type(module).__name__}")

    # Test forward pass with token sequence
    batch_size, seq_len = 2, 20
    tokens = torch.randint(0, config.vocab_size, (batch_size, seq_len))

    print(f"\nTesting model inference:")
    print(f"  Input tokens shape: {tokens.shape}")

    with torch.no_grad():
        # Test with targets for full sequence output
        logits, loss = model(tokens, targets=tokens)
        print(f"  Output logits shape: {logits.shape}")
        print(f"  Loss: {loss.item():.4f}")
        print(f"  Expected shape: ({batch_size}, {seq_len}, {config.vocab_size})")

        # Verify output dimensions
        expected_shape = (batch_size, seq_len, config.vocab_size)
        if logits.shape == expected_shape:
            print(f"  Shape verification: ‚úì Success")
        else:
            print(f"  Shape verification: ‚úó Failed")
            return False

        # Test inference mode (last position only)
        inference_logits, inference_loss = model(tokens)
        expected_inference_shape = (batch_size, 1, config.vocab_size)
        if inference_logits.shape == expected_inference_shape:
            print(f"  Inference mode shape: ‚úì Success {inference_logits.shape}")
        else:
            print(f"  Inference mode shape: ‚úó Failed {inference_logits.shape}")
            return False

    return True

def test_parameter_count():
    """Test parameter count reduction from removing LN1"""
    print("\n" + "=" * 60)
    print("Testing Parameter Count (LN1 Removal Impact)")
    print("=" * 60)

    config = PicoGPTConfig()
    model = PicoGPT(config)

    total_params = sum(p.numel() for p in model.parameters())
    print(f"Total parameters: {total_params:,}")

    # Count LN parameters
    ln_params = 0
    ln_count = 0
    for name, module in model.named_modules():
        if 'ln_' in name and hasattr(module, 'weight'):
            params = module.weight.numel()
            ln_params += params
            ln_count += 1
            print(f"  {name}: {params:,} parameters")

    print(f"\nLayerNorm summary:")
    print(f"  Total LN layers: {ln_count}")
    print(f"  Total LN parameters: {ln_params:,}")
    print(f"  LN1 layers removed: ‚úì {config.n_layer} layers saved")
    print(f"  Parameters saved: {config.n_layer * config.n_embd:,}")

    return True

def test_cimv3_sequence():
    """Verify the execution sequence matches CIMv3"""
    print("\n" + "=" * 60)
    print("Testing CIMv3 Execution Sequence")
    print("=" * 60)

    config = PicoGPTConfig(n_embd=128, n_head=2, dropout=0.0)
    block = Block(config)

    # Create test input
    x = torch.randn(1, 10, 128)

    print("CIMv3 Hardware Sequence:")
    print("  1. MHA (PIPE mode)")
    print("  2. FFN (PARL mode)")
    print("  3. LN2 (LN mode)")

    print("\npicoGPT Block Implementation:")
    print("  1. x = x + attn(x)     # MHA with residual")
    print("  2. x = ln_2(x + mlp(x)) # FFN + LN2 with residual")

    # Test execution
    with torch.no_grad():
        # Step 1: MHA
        attn_out = block.attn(x)
        x1 = x + attn_out
        print(f"  After MHA: shape {x1.shape} ‚úì")

        # Step 2: FFN + LN2
        mlp_out = block.mlp(x1)
        x2 = block.ln_2(x1 + mlp_out)
        print(f"  After FFN+LN2: shape {x2.shape} ‚úì")

        # Compare with full forward
        x_test = torch.randn(1, 10, 128)
        full_out = block(x_test)
        print(f"  Full forward: shape {full_out.shape} ‚úì")

    return True

def test_cimv3_constraints():
    """Test CIMv3 hardware constraints validation"""
    print("\n" + "=" * 60)
    print("Testing CIMv3 Hardware Constraints")
    print("=" * 60)

    # Test valid configurations
    print("Testing valid CIMv3 configurations:")

    for n_embd, n_head in [(128, 2), (256, 4), (512, 8)]:
        try:
            config = PicoGPTConfig(n_embd=n_embd, n_head=n_head, dropout=0.0)
            d_head = n_embd // n_head
            print(f"  ‚úì n_embd={n_embd}, n_head={n_head}, d_head={d_head}")
        except ValueError as e:
            print(f"  ‚úó n_embd={n_embd}, n_head={n_head}: {e}")
            return False

    # Test invalid configurations
    print("\nTesting invalid CIMv3 configurations:")

    # Invalid n_embd
    try:
        config = PicoGPTConfig(n_embd=100, n_head=2, dropout=0.0)
        print(f"  ‚úó Should have failed for n_embd=100")
        return False
    except ValueError:
        print(f"  ‚úì Correctly rejected n_embd=100")

    # Invalid n_head (not divisible)
    try:
        config = PicoGPTConfig(n_embd=128, n_head=3, dropout=0.0)
        print(f"  ‚úó Should have failed for non-divisible n_head")
        return False
    except ValueError:
        print(f"  ‚úì Correctly rejected n_embd=128, n_head=3")

    return True

if __name__ == "__main__":
    success = True

    success &= test_cimv3_block_structure()
    success &= test_full_model()
    success &= test_parameter_count()
    success &= test_cimv3_sequence()
    success &= test_cimv3_constraints()

    print("\n" + "=" * 60)
    if success:
        print("üöÄ ALL TESTS PASSED - CIMv3 Compatibility Verified!")
        print("‚úì LN1 removed from all blocks")
        print("‚úì Sequence: MHA ‚Üí FFN ‚Üí LN2")
        print("‚úì Hardware mapping: PIPE ‚Üí PARL ‚Üí LN modes")
        print("‚úì ReLU activation (CIMv3 compatible)")
        print("‚úì Hardware constraints validated")
        print("‚úì d_head=64 optimized configuration")
    else:
        print("‚ùå Some tests failed - check implementation")
    print("=" * 60)